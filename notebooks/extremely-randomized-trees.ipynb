{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('../titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev. Juozas Montvila</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss. Margaret Edith Graham</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Catherine Helen Johnston</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Karl Howell Behr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Patrick Dooley</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           0       3                             Mr. Owen Harris Braund   \n",
       "1           1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2           1       3                              Miss. Laina Heikkinen   \n",
       "3           1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4           0       3                            Mr. William Henry Allen   \n",
       "..        ...     ...                                                ...   \n",
       "882         0       2                               Rev. Juozas Montvila   \n",
       "883         1       1                        Miss. Margaret Edith Graham   \n",
       "884         0       3                     Miss. Catherine Helen Johnston   \n",
       "885         1       1                               Mr. Karl Howell Behr   \n",
       "886         0       3                                 Mr. Patrick Dooley   \n",
       "\n",
       "        Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0      male  22.0                        1                        0   7.2500  \n",
       "1    female  38.0                        1                        0  71.2833  \n",
       "2    female  26.0                        0                        0   7.9250  \n",
       "3    female  35.0                        1                        0  53.1000  \n",
       "4      male  35.0                        0                        0   8.0500  \n",
       "..      ...   ...                      ...                      ...      ...  \n",
       "882    male  27.0                        0                        0  13.0000  \n",
       "883  female  19.0                        0                        0  30.0000  \n",
       "884  female   7.0                        1                        2  23.4500  \n",
       "885    male  26.0                        0                        0  30.0000  \n",
       "886    male  32.0                        0                        0   7.7500  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_sex(row):\n",
    "    if row['Sex'] == 'male':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "samples['sex_int'] = samples.apply(lambda row: int_sex(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_samples, test_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split:\n",
    "    def __init__(self, attribute, cut_off, left_node, right_node):\n",
    "        self.attribute = attribute\n",
    "        self.cut_off = cut_off\n",
    "        self.left_node = left_node\n",
    "        self.right_node = right_node\n",
    "        \n",
    "    def predict(self, sample):\n",
    "        if sample[self.attribute] < self.cut_off:\n",
    "            return self.left_node.predict(sample)\n",
    "        else:\n",
    "            return self.right_node.predict(sample)\n",
    "        \n",
    "    def predict_proba(self, sample):\n",
    "        if sample[self.attribute] < self.cut_off:\n",
    "            return self.left_node.predict(sample)\n",
    "        else:\n",
    "            return self.right_node.predict(sample)        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'Split(' + str(self.attribute) + ', ' + str(self.cut_off) + \\\n",
    "            ', [' + str(self.left_node) + ', ' +  str(self.right_node) + '])'\n",
    "        \n",
    "class Leaf:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "\n",
    "    def predict(self, sample):\n",
    "        if self.label > 0.5:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "    def predict_proba(self, sample):\n",
    "        return self.label                \n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'Leaf(' + str(self.label) + ')'\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(a, b, a_plus_b):    \n",
    "    #print('\\t\\t', a, b, a_plus_b)\n",
    "    \n",
    "    if a == 0 and b == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    p_a = float(a) / float(a_plus_b)\n",
    "    p_b = float(b) / float(a_plus_b)\n",
    "    \n",
    "    log2_p_a = 0.0\n",
    "    if a != 0:\n",
    "        log2_p_a = np.log2(p_a)\n",
    "        \n",
    "    log2_p_b = 0.0\n",
    "    if b != 0:\n",
    "        log2_p_b = np.log2(p_b)        \n",
    "        \n",
    "    return -(p_a * log2_p_a + p_b * log2_p_b)\n",
    "\n",
    "def split_score(num_plus_left, num_minus_left, num_plus_right, num_minus_right):\n",
    "    \n",
    "    #print('\\tComputing score for ', num_plus_left, num_minus_left, num_plus_right, num_minus_right)\n",
    "    \n",
    "    num_left = num_plus_left + num_minus_left\n",
    "    num_right = num_plus_right + num_minus_right\n",
    "    num_plus = num_plus_left + num_plus_right\n",
    "    num_minus = num_minus_left + num_minus_right\n",
    "\n",
    "    num_samples = num_left + num_right\n",
    "\n",
    "    # Prior \"classification entropy\" H_C(S)\n",
    "    hcs = H(num_plus, num_minus, num_samples)\n",
    "\n",
    "    # Entropy of S with respect to test T H_T(S)\n",
    "    hts = H(num_left, num_right, num_samples)\n",
    "\n",
    "    # Posterior \"classification entropy\" H_{C|T}(S) of S given the outcome of the test T\n",
    "    p_sys = float(num_left) / float(num_samples)\n",
    "    p_sns = float(num_right) / float(num_samples)\n",
    "\n",
    "    hcsy = H(num_plus_left, num_minus_left, num_left)\n",
    "    hcsn = H(num_plus_right, num_minus_right, num_right)\n",
    "\n",
    "    hcts = p_sys * hcsy + p_sns * hcsn;\n",
    "\n",
    "    # Information gain of applying test T\n",
    "    icts = hcs - hcts;\n",
    "\n",
    "    score = 2.0 * icts / (hcs + hts);\n",
    "    \n",
    "    return score\n",
    "\n",
    "def split(samples, attribute_candidates, label_attribute, d):\n",
    "\n",
    "    # TODO check that the attribute is non-constant\n",
    "    \n",
    "    attributes = np.random.choice(attribute_candidates, d, replace=False)\n",
    "    \n",
    "    max_score = -1\n",
    "    the_attribute = None\n",
    "    the_cutoff = None\n",
    "    the_left_samples = None\n",
    "    the_right_samples = None\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        attribute_values = np.array(samples[attribute])\n",
    "\n",
    "        min_attribute_value = np.min(attribute_values)\n",
    "        max_attribute_value = np.max(attribute_values)\n",
    "\n",
    "        cut_off = np.random.uniform(min_attribute_value, max_attribute_value)    \n",
    "\n",
    "        left_samples = samples[samples[attribute] < cut_off].copy(deep=True)\n",
    "        right_samples = samples[samples[attribute] >= cut_off].copy(deep=True)\n",
    "\n",
    "        num_plus_left = np.sum(left_samples[label_attribute] == 1)\n",
    "        num_minus_left = np.sum(left_samples[label_attribute] == 0)\n",
    "        num_plus_right = np.sum(right_samples[label_attribute] == 1)\n",
    "        num_minus_right = np.sum(right_samples[label_attribute] == 0)\n",
    "\n",
    "        score = split_score(num_plus_left, num_minus_left, num_plus_right, num_minus_right)\n",
    "        \n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            the_attribute = attribute\n",
    "            the_cutoff = cut_off\n",
    "            the_left_samples = left_samples\n",
    "            the_right_samples = right_samples            \n",
    "    \n",
    "    return the_attribute, the_cutoff, left_samples, right_samples, max_score    \n",
    "\n",
    "def stop_split(samples, attribute_candidates, label_attribute, n_min):\n",
    "    \n",
    "    if len(samples) < n_min:\n",
    "        return True\n",
    "    \n",
    "    for attribute in attribute_candidates:\n",
    "        if len(samples[attribute].unique()) == 1:\n",
    "            return True\n",
    "    \n",
    "    if len(samples[label_attribute].unique()) == 1:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def split_node(samples, attribute_candidates, label_attribute, d, n_min):\n",
    "    \n",
    "    if stop_split(samples, attribute_candidates, label_attribute, n_min):\n",
    "        \n",
    "        num_positive = float(np.sum(samples[label_attribute]))\n",
    "        label = num_positive / len(samples[label_attribute])\n",
    "        \n",
    "        return Leaf(label)\n",
    "    \n",
    "    attribute, cut_off, left_samples, right_samples, score = \\\n",
    "        split(samples, attribute_candidates, label_attribute, d)\n",
    "    \n",
    "    #print('Splitting', len(samples), 'samples on', attribute, 'with cut_off', cut_off, 'and score', score, \n",
    "    #     len(left_samples), len(right_samples))\n",
    "    \n",
    "    left_child = split_node(left_samples, attribute_candidates, label_attribute, n_min, d)        \n",
    "    right_child = split_node(right_samples, attribute_candidates, label_attribute, n_min, d)\n",
    "    \n",
    "    return Split(attribute, cut_off, left_child, right_child)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = 100\n",
    "d = 5\n",
    "n_min = 3\n",
    "\n",
    "attribute_candidates = ['Age', 'Pclass', 'Fare', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'sex_int']\n",
    "label_attribute = 'Survived'\n",
    "        \n",
    "trees = []\n",
    "for _ in range(0, num_trees):\n",
    "    trees.append(split_node(train_samples, attribute_candidates, label_attribute, d, n_min))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146067415730337"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "true_classes = test_samples[label_attribute]\n",
    "predicted_classes = []\n",
    "\n",
    "for row in range(0, len(test_samples)):\n",
    "    \n",
    "    predictions = [tree.predict(test_samples.iloc[row]) for tree in trees]\n",
    "    num_positive = np.sum(predictions)\n",
    "    if num_positive > len(predictions) / 2:\n",
    "        predicted_class = 1\n",
    "    else:\n",
    "        predicted_class = 0\n",
    "    \n",
    "    predicted_classes.append(predicted_class)\n",
    "    \n",
    "accuracy_score(true_classes, predicted_classes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7079646017699116"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  15],\n",
       "       [ 18,  40]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X_train = train_samples[attribute_candidates].values\n",
    "y_train = train_samples[label_attribute].values\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7471910112359551"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_samples[attribute_candidates].values\n",
    "y_test = test_samples[label_attribute].values\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93, 27],\n",
       "       [18, 40]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
